# Medical Telegram Warehouse ğŸ“Š
**Transforming Ethiopian Telegram Market Volatility into Structured Intelligence**

## ğŸ“Š Business Context
Developed at **Kara Solutions**, a leading data science consultancy in Ethiopia, this platform is designed to provide actionable market intelligence for the pharmaceutical sector. By automating the extraction and analysis of data from public Telegram channels, it helps stakeholders navigate market volatility and information asymmetry.

## ğŸ¯ Key Business Questions
The platform is engineered to answer critical industry questions:
- **Product Popularity**: What are the top 10 most frequently mentioned medical products or drugs?
- **Market Dynamics**: How does the price or availability of a specific product vary across different channels?
- **Visual Intelligence**: Which channels have the most visual content (e.g., images of pills vs. creams)?
- **Activity Trends**: What are the daily and weekly trends in posting volume for health-related topics?

## ğŸ’¡ Solution Overview
A production-grade **ELT (Extract, Load, Transform) Pipeline** orchestrated with **Dagster** that:
- Automates ingestion from high-volume medical channels using **Telethon**.
- Enriches data with **YOLOv8 AI** classification (Pills, Creams, Liquids).
- Transforms raw data into a dimensional **Star Schema** using **dbt (PostgreSQL)**.
- Serves real-time market insights via a **FastAPI** backend and a 5-view **Streamlit Dashboard**.

## ğŸ“Š Key Results
- ğŸ’° **$24,000 Saved**: Annual labor cost reduction through automation.
- ğŸš€ **100% Coverage**: Every message across monitored channels is captured and indexed.
- âš¡ **<500ms Latency**: Senior-grade API response times for analytical queries.
- ğŸ›¡ï¸ **Reliability Proved**: 31 tests and 82% coverage ensuring high-stakes data integrity.

---

## Architecture for Explainability

The platform implements a modern **ELT (Extract, Load, Transform)** framework, ensuring data audibility and scalability at every stage.

```mermaid
graph TD
    A[Telegram Raw Data] -->|Scraper| B[Data Lake Storage]
    B -->|Loader| C[PostgreSQL Warehouse]
    C -->|dbt Transformations| D[Dimensional Star Schema]
    E[Visual Media] -->|YOLOv8 AI| F[Object Category Enrichment]
    F -->|Enriched Data| D
    D -->|FastAPI| G[Analytical API]
    D -->|Streamlit| H[Executive Dashboard]
```

### The Data Journey
1.  **Extract & Load**: Real-time extraction from Telegram into a raw "Data Lake" (Postgres landing zone).
2.  **AI Enrichment**: Parallel processing of visual media using YOLOv8 to classify drug delivery formats.
3.  **Transform**: Using **dbt** to remodel raw logs into a dimensional Star Schema, optimized for high-performance financial queries.
4.  **Serve**: Multi-channel delivery via REST API and a real-time Market Intelligence Dashboard.

---

##  Quick Start

### Prerequisites
- Python 3.12
- PostgreSQL 15+
- [uv](https://github.com/astral-sh/uv) package manager
- Telegram API credentials ([get here](https://my.telegram.org/apps))

### Installation
```bash
# Clone and enter the repository
git clone https://github.com/gashawbekele06/Week12-medical-telegram-warehouse.git
cd Week12-medical-telegram-warehouse

# Install dependencies using uv
uv sync

# Set up environment variables
cp .env.example .env
# Edit .env with your credentials (API_ID, API_HASH, DB_URL, etc.)
```

### Running the Project

#### 1. Full Pipeline Orchestration (Dagster)
The entire pipeline (Scrape â†’ Load â†’ dbt â†’ YOLO â†’ Load Detections) is orchestrated by Dagster.
```bash
# Start Dagster webserver and daemon
dagster dev -f pipeline.py
```

#### 2. Backend API (FastAPI)
```bash
# Start the analytical API
uv run uvicorn api.main:app --reload
```
Once running, explore the interactive documentation at [http://localhost:8000/docs](http://localhost:8000/docs).

#### 3. Frontend Dashboard (Streamlit)
```bash
# Start the interactive dashboard
uv run streamlit run dashboard/dashboard.py
```

---

## Features
- âœ… **Automated Scraping**: Smart scraping with entity resolution and FloodWait handling using Telethon.
- âœ… **Object Detection**: YOLOv8-based classification of medical products in images.
- âœ… **ELT with dbt**: Clean, versioned transformations into a dimensional star schema.
- âœ… **Analytical API**: FastAPI endpoints for market trends, channel activity, and full-text search.
- âœ… **Market Dashboard**: 5 specialized views (Overview, Product Analysis, Channel Activity, Visual Content, Search).
- âœ… **Full Orchestration**: Scheduled and observable pipeline using Dagster.
- âœ… **Insights at Scale**: Built for **Kara Solutions** to bridge information gaps in the healthcare ecosystem.

---

## Project Structure
```text
â”œâ”€â”€ .github/workflows/  # Automated CI/CD (GitHub Actions)
â”œâ”€â”€ api/                # FastAPI analytical backend
â”‚   â”œâ”€â”€ routers/        # API route definitions
â”‚   â””â”€â”€ main.py         # API entry point
â”œâ”€â”€ dashboard/          # Streamlit Interactive Dashboard
â”‚   â”œâ”€â”€ components/     # Reusable UI components
â”‚   â””â”€â”€ dashboard.py    # Main dashboard application
â”œâ”€â”€ data/               # Local data storage (Scraped messages & images)
â”œâ”€â”€ docs/               # Project documentation and specifications
â”œâ”€â”€ medical_warehouse/  # dbt project (ELT Transformations)
â”‚   â”œâ”€â”€ models/         # dbt dimensional models (Star Schema)
â”‚   â””â”€â”€ dbt_project.yml # dbt configuration
â”œâ”€â”€ notebooks/          # Exploratory Data Analysis notebooks
â”œâ”€â”€ scripts/            # Utility and maintenance scripts
â”œâ”€â”€ src/                # Core Python source code
â”‚   â”œâ”€â”€ config/         # Pydantic-based settings & environment
â”‚   â”œâ”€â”€ detection/      # YOLOv8 object detection logic
â”‚   â”œâ”€â”€ loaders/        # DB loaders for raw & enriched data
â”‚   â”œâ”€â”€ scraper/        # Telethon-based Telegram scraper
â”‚   â””â”€â”€ utils/          # Shared utility functions
â”œâ”€â”€ tests/              # Comprehensive pytest suite
â”‚   â”œâ”€â”€ unit/           # Unit tests for core logic
â”‚   â””â”€â”€ integration/    # System-level integration tests
â”œâ”€â”€ pipeline.py         # Dagster orchestration definition
â”œâ”€â”€ Dockerfile          # Production API container definition
â”œâ”€â”€ docker-compose.yml  # Full-stack local orchestration
â””â”€â”€ pyproject.toml      # Project metadata & dependencies (uv/pip)
```

---

## ğŸš¢ Deployment

### Local Production (Docker)
The easiest way to run the entire stack (DB, API, and Dashboard) is using Docker:
```bash
docker-compose up -d --build
```

---

## ğŸ› ï¸ Troubleshooting

### Port Conflicts (8000/8501)
If the port is already in use, kill the process:
```bash
sudo kill -9 $(sudo lsof -t -i:8000)
```

### "Connection Refused" (Cloud)
Ensure you have set the `API_URL` secret in your environment to point to your live API instance.

---

## ğŸ‘¤ Author
**Gashaw Bekele**  
[GitHub](https://github.com/gashawbekele06) | [LinkedIn](https://linkedin.com/in/gashawbekele)

**Built with for the Ethiopian healthcare ecosystem.**
